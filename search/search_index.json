{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"prefect-openmetadata Welcome! Using Prefect and OpenMetadata together will help you build and maintain a data platform you can trust . Prefect allows you to orchestrate your data workflows and provides visibility into the health of your workflow execution and workflow lineage . With OpenMetadata integration, you can enrich your orchestration system with metadata about data lineage, data catalog, data quality and governance, giving you a single pane of glass about the health of your system. Getting Started Python setup Requires an installation of Python 3.8+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. This prefect-openmetadata package is designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the documentation . Installation Install prefect-openmetadata with pip : pip install prefect-openmetadata Install OpenMetadata and Prefect 2.0 Head over to the install OpenMetadata page for detailed instructions on how to install and configure both platforms. Write and run metadata ingestion flow from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in the section: Run ingestion flow\"\"\" if __name__ == \"__main__\" : ingest_metadata ( json_config ) For more details, check the run ingestion flow section. Schedule a metadata ingestion flow Simple example: DeploymentSpec ( name = \"openmetadata-dev\" , flow = ingest_metadata , schedule = IntervalSchedule ( interval = timedelta ( minutes = 15 )), ) For more details, check the schedule ingestion flow section. Resources If you encounter any bugs while using prefect-openmetadata , feel free to open an issue in the prefect-openmetadata repository. If you have any questions or issues while using prefect-openmetadata , you can find help in either the Prefect Discourse forum or the Prefect Slack community . Development If you'd like to install a version of prefect-openmetadata for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-openmetadata.git cd prefect-openmetadata/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Home"},{"location":"#prefect-openmetadata","text":"","title":"prefect-openmetadata"},{"location":"#welcome","text":"Using Prefect and OpenMetadata together will help you build and maintain a data platform you can trust . Prefect allows you to orchestrate your data workflows and provides visibility into the health of your workflow execution and workflow lineage . With OpenMetadata integration, you can enrich your orchestration system with metadata about data lineage, data catalog, data quality and governance, giving you a single pane of glass about the health of your system.","title":"Welcome!"},{"location":"#getting-started","text":"","title":"Getting Started"},{"location":"#python-setup","text":"Requires an installation of Python 3.8+. We recommend using a Python virtual environment manager such as pipenv, conda or virtualenv. This prefect-openmetadata package is designed to work with Prefect 2.0. For more information about how to use Prefect, please refer to the documentation .","title":"Python setup"},{"location":"#installation","text":"Install prefect-openmetadata with pip : pip install prefect-openmetadata","title":"Installation"},{"location":"#install-openmetadata-and-prefect-20","text":"Head over to the install OpenMetadata page for detailed instructions on how to install and configure both platforms.","title":"Install OpenMetadata and Prefect 2.0"},{"location":"#write-and-run-metadata-ingestion-flow","text":"from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in the section: Run ingestion flow\"\"\" if __name__ == \"__main__\" : ingest_metadata ( json_config ) For more details, check the run ingestion flow section.","title":"Write and run metadata ingestion flow"},{"location":"#schedule-a-metadata-ingestion-flow","text":"Simple example: DeploymentSpec ( name = \"openmetadata-dev\" , flow = ingest_metadata , schedule = IntervalSchedule ( interval = timedelta ( minutes = 15 )), ) For more details, check the schedule ingestion flow section.","title":"Schedule a metadata ingestion flow"},{"location":"#resources","text":"If you encounter any bugs while using prefect-openmetadata , feel free to open an issue in the prefect-openmetadata repository. If you have any questions or issues while using prefect-openmetadata , you can find help in either the Prefect Discourse forum or the Prefect Slack community .","title":"Resources"},{"location":"#development","text":"If you'd like to install a version of prefect-openmetadata for development, clone the repository and perform an editable install with pip : git clone https://github.com/PrefectHQ/prefect-openmetadata.git cd prefect-openmetadata/ pip install -e \".[dev]\" # Install linting pre-commit hooks pre-commit install","title":"Development"},{"location":"flows/","text":"prefect_openmetadata.flows Prefect flow for metadata ingestion Follow the main documentation for guidance on: installing and configuring Prefect and OpenMetadata , running metadata ingestion flows locally and on schedule. ingest_metadata Parameters: Name Type Description Default config str JSON-formatted configuration required Examples: Flow ingesting metadata using Prefect: from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in the section: Run ingestion flow\"\"\" if __name__ == \"__main__\" : ingest_metadata ( json_config ) Source code in prefect_openmetadata/flows.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @flow def ingest_metadata ( config : str ) -> None : \"\"\" Args: config: JSON-formatted configuration Examples: Flow ingesting metadata using Prefect: ```python from prefect_openmetadata.flows import ingest_metadata json_config = \\\"\"\" See an example in the section : Run ingestion flow \\ \"\"\" if __name__ == \"__main__\": ingest_metadata(json_config) ``` \"\"\" workflow_config = json . loads ( config ) workflow = PrefectOpenMetadataIngestion . create ( workflow_config ) workflow . execute () workflow . raise_from_status () workflow . log_flow_status () workflow . stop ()","title":"Flow examples"},{"location":"flows/#prefect_openmetadata.flows","text":"","title":"flows"},{"location":"flows/#prefect_openmetadata.flows--prefect-flow-for-metadata-ingestion","text":"Follow the main documentation for guidance on: installing and configuring Prefect and OpenMetadata , running metadata ingestion flows locally and on schedule.","title":"Prefect flow for metadata ingestion"},{"location":"flows/#prefect_openmetadata.flows.ingest_metadata","text":"Parameters: Name Type Description Default config str JSON-formatted configuration required Examples: Flow ingesting metadata using Prefect: from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in the section: Run ingestion flow\"\"\" if __name__ == \"__main__\" : ingest_metadata ( json_config ) Source code in prefect_openmetadata/flows.py 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @flow def ingest_metadata ( config : str ) -> None : \"\"\" Args: config: JSON-formatted configuration Examples: Flow ingesting metadata using Prefect: ```python from prefect_openmetadata.flows import ingest_metadata json_config = \\\"\"\" See an example in the section : Run ingestion flow \\ \"\"\" if __name__ == \"__main__\": ingest_metadata(json_config) ``` \"\"\" workflow_config = json . loads ( config ) workflow = PrefectOpenMetadataIngestion . create ( workflow_config ) workflow . execute () workflow . raise_from_status () workflow . log_flow_status () workflow . stop ()","title":"ingest_metadata()"},{"location":"ingestion_workflow/","text":"prefect_openmetadata.ingestion_workflow Extention to the OpenMetadata Workflow class PrefectOpenMetadataIngestion OpenMetadata ingestion workflow that adds a method allowing to log the workflow status to the Prefect backend. Parameters: Name Type Description Default config string with a JSON configuration file required Source code in prefect_openmetadata/ingestion_workflow.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class PrefectOpenMetadataIngestion ( Workflow ): \"\"\" OpenMetadata ingestion workflow that adds a method allowing to log the workflow status to the Prefect backend. Args: config: string with a JSON configuration file \"\"\" def __int__ ( self , config : OpenMetadataWorkflowConfig ): \"\"\" Args: config: string with a JSON configuration file \"\"\" super () . __init__ ( config = config ) def log_flow_status ( self ) -> None : \"\"\" Log workflow status to the Prefect API backend \"\"\" logger = get_run_logger () logger . info ( \"Source Status: %s \" , self . source . get_status () . as_string ()) if hasattr ( self , \"stage\" ): logger . info ( \"Stage Status: %s \" , self . stage . get_status () . as_string ()) if hasattr ( self , \"sink\" ): logger . info ( \"Sink Status: %s \" , self . sink . get_status () . as_string ()) if hasattr ( self , \"bulk_sink\" ): logger . info ( \"Bulk Sink Status: %s \" , self . bulk_sink . get_status () . as_string ()) __int__ Parameters: Name Type Description Default config OpenMetadataWorkflowConfig string with a JSON configuration file required Source code in prefect_openmetadata/ingestion_workflow.py 20 21 22 23 24 25 def __int__ ( self , config : OpenMetadataWorkflowConfig ): \"\"\" Args: config: string with a JSON configuration file \"\"\" super () . __init__ ( config = config ) log_flow_status Log workflow status to the Prefect API backend Source code in prefect_openmetadata/ingestion_workflow.py 27 28 29 30 31 32 33 34 35 36 37 38 def log_flow_status ( self ) -> None : \"\"\" Log workflow status to the Prefect API backend \"\"\" logger = get_run_logger () logger . info ( \"Source Status: %s \" , self . source . get_status () . as_string ()) if hasattr ( self , \"stage\" ): logger . info ( \"Stage Status: %s \" , self . stage . get_status () . as_string ()) if hasattr ( self , \"sink\" ): logger . info ( \"Sink Status: %s \" , self . sink . get_status () . as_string ()) if hasattr ( self , \"bulk_sink\" ): logger . info ( \"Bulk Sink Status: %s \" , self . bulk_sink . get_status () . as_string ())","title":"Ingestion workflow module"},{"location":"ingestion_workflow/#prefect_openmetadata.ingestion_workflow","text":"Extention to the OpenMetadata Workflow class","title":"ingestion_workflow"},{"location":"ingestion_workflow/#prefect_openmetadata.ingestion_workflow.PrefectOpenMetadataIngestion","text":"OpenMetadata ingestion workflow that adds a method allowing to log the workflow status to the Prefect backend. Parameters: Name Type Description Default config string with a JSON configuration file required Source code in prefect_openmetadata/ingestion_workflow.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 class PrefectOpenMetadataIngestion ( Workflow ): \"\"\" OpenMetadata ingestion workflow that adds a method allowing to log the workflow status to the Prefect backend. Args: config: string with a JSON configuration file \"\"\" def __int__ ( self , config : OpenMetadataWorkflowConfig ): \"\"\" Args: config: string with a JSON configuration file \"\"\" super () . __init__ ( config = config ) def log_flow_status ( self ) -> None : \"\"\" Log workflow status to the Prefect API backend \"\"\" logger = get_run_logger () logger . info ( \"Source Status: %s \" , self . source . get_status () . as_string ()) if hasattr ( self , \"stage\" ): logger . info ( \"Stage Status: %s \" , self . stage . get_status () . as_string ()) if hasattr ( self , \"sink\" ): logger . info ( \"Sink Status: %s \" , self . sink . get_status () . as_string ()) if hasattr ( self , \"bulk_sink\" ): logger . info ( \"Bulk Sink Status: %s \" , self . bulk_sink . get_status () . as_string ())","title":"PrefectOpenMetadataIngestion"},{"location":"ingestion_workflow/#prefect_openmetadata.ingestion_workflow.PrefectOpenMetadataIngestion.__int__","text":"Parameters: Name Type Description Default config OpenMetadataWorkflowConfig string with a JSON configuration file required Source code in prefect_openmetadata/ingestion_workflow.py 20 21 22 23 24 25 def __int__ ( self , config : OpenMetadataWorkflowConfig ): \"\"\" Args: config: string with a JSON configuration file \"\"\" super () . __init__ ( config = config )","title":"__int__()"},{"location":"ingestion_workflow/#prefect_openmetadata.ingestion_workflow.PrefectOpenMetadataIngestion.log_flow_status","text":"Log workflow status to the Prefect API backend Source code in prefect_openmetadata/ingestion_workflow.py 27 28 29 30 31 32 33 34 35 36 37 38 def log_flow_status ( self ) -> None : \"\"\" Log workflow status to the Prefect API backend \"\"\" logger = get_run_logger () logger . info ( \"Source Status: %s \" , self . source . get_status () . as_string ()) if hasattr ( self , \"stage\" ): logger . info ( \"Stage Status: %s \" , self . stage . get_status () . as_string ()) if hasattr ( self , \"sink\" ): logger . info ( \"Sink Status: %s \" , self . sink . get_status () . as_string ()) if hasattr ( self , \"bulk_sink\" ): logger . info ( \"Bulk Sink Status: %s \" , self . bulk_sink . get_status () . as_string ())","title":"log_flow_status()"},{"location":"install_openmetadata/","text":"Install OpenMetadata Requirements Please ensure your host system meets the requirements listed below: Python 3.8+ Docker 20.10.0+ Docker Compose Installing OpenMetadata Clone the prefect-openmetadata repository First, clone the latest version of the prefect-openmetadata Prefect Collection. Then, navigate to the directory openmetadata-docker containing the docker-compose.yml file with the minimal requirements to get started with OpenMetadata. Start OpenMetadata containers You can start the containers with OpenMetadata components using: docker compose up -d This will create a docker network and containers with the following services: openmetadata_mysql - metadata store that serves as a persistence layer holding your metadata, openmetadata_elasticsearch - indexing service to search the metadata catalog, openmetadata_server - the OpenMetadata UI and API server allowing you to discover insights and interact with your metadata. Wait a couple of minutes until the setup is finished. To check the status of all services, you may run the docker compose ps command to investigate the status of all Docker containers: NAME COMMAND SERVICE STATUS PORTS openmetadata_elasticsearch \"/tini -- /usr/local\u2026\" elasticsearch running 0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp openmetadata_mysql \"/entrypoint.sh mysq\u2026\" mysql running (healthy) 33060-33061/tcp openmetadata_server \"./openmetadata-star\u2026\" openmetadata-server running 0.0.0.0:8585->8585/tcp Confirm you can access the OpenMetadata UI Visit the following URL to confirm you can access the UI and start exploring OpenMetadata: http://localhost:8585 You should see a page similar to the following as the landing page for the OpenMetadata UI. Why should you use Prefect for metadata ingestion? The challenge with the metadata ingestion is to ensure that this process can be automated and can run reliably , either on a regular interval, or ad-hoc. This is where Prefect can help. Prefect 2.0 is a general-purpose workflow orchestration platform allowing you to build, run, schedule, and operationalize your data pipelines at scale. It supports both batch and streaming workflows and provides an excellent developer experience allowing you to run your flows locally and seamlessly move to production and to Cloud when you\u2019re ready. Among many other features , it natively supports: dynamic runtime-discoverable and modular workflows, passing data between tasks, running your workflows on various execution platforms (on-prem, cloud, Docker, Kubernetes) while maintaining privacy via a hybrid execution model , scaling out for parallel and concurrent execution with async, Dask, and Ray , various integrations through Prefect Collections - such as this one! Install Prefect You can install Prefect using a single command: pip install -U \"prefect>=2.0b\" This will not only install the client library, but also an embedded API server and UI, which can optionally be started using: prefect orion start If you navigate to the URL, you\u2019ll be able to access a locally running Prefect Orion UI: http://localhost:4200","title":"Install OpenMetadata"},{"location":"install_openmetadata/#install-openmetadata","text":"","title":"Install OpenMetadata"},{"location":"install_openmetadata/#requirements","text":"Please ensure your host system meets the requirements listed below: Python 3.8+ Docker 20.10.0+ Docker Compose","title":"Requirements"},{"location":"install_openmetadata/#installing-openmetadata","text":"","title":"Installing OpenMetadata"},{"location":"install_openmetadata/#clone-the-prefect-openmetadata-repository","text":"First, clone the latest version of the prefect-openmetadata Prefect Collection. Then, navigate to the directory openmetadata-docker containing the docker-compose.yml file with the minimal requirements to get started with OpenMetadata.","title":"Clone the prefect-openmetadata repository"},{"location":"install_openmetadata/#start-openmetadata-containers","text":"You can start the containers with OpenMetadata components using: docker compose up -d This will create a docker network and containers with the following services: openmetadata_mysql - metadata store that serves as a persistence layer holding your metadata, openmetadata_elasticsearch - indexing service to search the metadata catalog, openmetadata_server - the OpenMetadata UI and API server allowing you to discover insights and interact with your metadata. Wait a couple of minutes until the setup is finished. To check the status of all services, you may run the docker compose ps command to investigate the status of all Docker containers: NAME COMMAND SERVICE STATUS PORTS openmetadata_elasticsearch \"/tini -- /usr/local\u2026\" elasticsearch running 0.0.0.0:9200->9200/tcp, 0.0.0.0:9300->9300/tcp openmetadata_mysql \"/entrypoint.sh mysq\u2026\" mysql running (healthy) 33060-33061/tcp openmetadata_server \"./openmetadata-star\u2026\" openmetadata-server running 0.0.0.0:8585->8585/tcp","title":"Start OpenMetadata containers"},{"location":"install_openmetadata/#confirm-you-can-access-the-openmetadata-ui","text":"Visit the following URL to confirm you can access the UI and start exploring OpenMetadata: http://localhost:8585 You should see a page similar to the following as the landing page for the OpenMetadata UI.","title":"Confirm you can access the OpenMetadata UI"},{"location":"install_openmetadata/#why-should-you-use-prefect-for-metadata-ingestion","text":"The challenge with the metadata ingestion is to ensure that this process can be automated and can run reliably , either on a regular interval, or ad-hoc. This is where Prefect can help. Prefect 2.0 is a general-purpose workflow orchestration platform allowing you to build, run, schedule, and operationalize your data pipelines at scale. It supports both batch and streaming workflows and provides an excellent developer experience allowing you to run your flows locally and seamlessly move to production and to Cloud when you\u2019re ready. Among many other features , it natively supports: dynamic runtime-discoverable and modular workflows, passing data between tasks, running your workflows on various execution platforms (on-prem, cloud, Docker, Kubernetes) while maintaining privacy via a hybrid execution model , scaling out for parallel and concurrent execution with async, Dask, and Ray , various integrations through Prefect Collections - such as this one!","title":"Why should you use Prefect for metadata ingestion?"},{"location":"install_openmetadata/#install-prefect","text":"You can install Prefect using a single command: pip install -U \"prefect>=2.0b\" This will not only install the client library, but also an embedded API server and UI, which can optionally be started using: prefect orion start If you navigate to the URL, you\u2019ll be able to access a locally running Prefect Orion UI: http://localhost:4200","title":"Install Prefect"},{"location":"run_ingestion_flow/","text":"Run metadata ingestion Configure your ingestion spec In the Install OpenMetadata section, you cloned the prefect-openmetadata repository. This repository contains a directory example-data which you can use to ingest sample data into your OpenMetadata backend using Prefect. Here is a JSON configuration you can use in your flow to ingest that sample data: { \"source\" : { \"type\" : \"sample-data\" , \"serviceName\" : \"sample_data\" , \"serviceConnection\" : { \"config\" : { \"type\" : \"SampleData\" , \"sampleDataFolder\" : \"example-data\" } }, \"sourceConfig\" : {} }, \"sink\" : { \"type\" : \"metadata-rest\" , \"config\" : {} }, \"workflowConfig\" : { \"openMetadataServerConfig\" : { \"hostPort\" : \"http://localhost:8585/api\" , \"authProvider\" : \"no-auth\" } } } Run ingestion workflow locally Now you can paste the JSON-config from above as a string into your flow and run it: from prefect_openmetadata.flows import ingest_metadata config = \"\"\" { \"source\": { \"type\": \"sample-data\", \"serviceName\": \"sample_data\", \"serviceConnection\": { \"config\": { \"type\": \"SampleData\", \"sampleDataFolder\": \"example-data\" } }, \"sourceConfig\": {} }, \"sink\": { \"type\": \"metadata-rest\", \"config\": {} }, \"workflowConfig\": { \"openMetadataServerConfig\": { \"hostPort\": \"http://localhost:8585/api\", \"authProvider\": \"no-auth\" } } } \"\"\" if __name__ == \"__main__\" : ingest_metadata ( config ) After running your flow, you should see new users , datasets , dashboards, and other metadata in your OpenMetadata UI. Also, your Prefect UI will display the workflow run and will show the logs with details on which source system has been scanned and which data has been ingested. Congratulations on building your first metadata ingestion workflow with OpenMetadata and Prefect! Head over to the next section to see how you can run this flow on schedule.","title":"Run ingestion flow"},{"location":"run_ingestion_flow/#run-metadata-ingestion","text":"","title":"Run metadata ingestion"},{"location":"run_ingestion_flow/#configure-your-ingestion-spec","text":"In the Install OpenMetadata section, you cloned the prefect-openmetadata repository. This repository contains a directory example-data which you can use to ingest sample data into your OpenMetadata backend using Prefect. Here is a JSON configuration you can use in your flow to ingest that sample data: { \"source\" : { \"type\" : \"sample-data\" , \"serviceName\" : \"sample_data\" , \"serviceConnection\" : { \"config\" : { \"type\" : \"SampleData\" , \"sampleDataFolder\" : \"example-data\" } }, \"sourceConfig\" : {} }, \"sink\" : { \"type\" : \"metadata-rest\" , \"config\" : {} }, \"workflowConfig\" : { \"openMetadataServerConfig\" : { \"hostPort\" : \"http://localhost:8585/api\" , \"authProvider\" : \"no-auth\" } } }","title":"Configure your ingestion spec"},{"location":"run_ingestion_flow/#run-ingestion-workflow-locally","text":"Now you can paste the JSON-config from above as a string into your flow and run it: from prefect_openmetadata.flows import ingest_metadata config = \"\"\" { \"source\": { \"type\": \"sample-data\", \"serviceName\": \"sample_data\", \"serviceConnection\": { \"config\": { \"type\": \"SampleData\", \"sampleDataFolder\": \"example-data\" } }, \"sourceConfig\": {} }, \"sink\": { \"type\": \"metadata-rest\", \"config\": {} }, \"workflowConfig\": { \"openMetadataServerConfig\": { \"hostPort\": \"http://localhost:8585/api\", \"authProvider\": \"no-auth\" } } } \"\"\" if __name__ == \"__main__\" : ingest_metadata ( config ) After running your flow, you should see new users , datasets , dashboards, and other metadata in your OpenMetadata UI. Also, your Prefect UI will display the workflow run and will show the logs with details on which source system has been scanned and which data has been ingested. Congratulations on building your first metadata ingestion workflow with OpenMetadata and Prefect! Head over to the next section to see how you can run this flow on schedule.","title":"Run ingestion workflow locally"},{"location":"schedule_ingestion_flow/","text":"Schedule and deploy metadata ingestion flows Schedule your OpenMetadata ingestion flows with Prefect Ingesting your data via manually executed scripts is great for initial exploration, but in order to build a reliable metadata platform, you need to run those workflows on a regular cadence. That\u2019s where you can leverage Prefect schedules and deployments . Here is how you can add a DeploymentSpec to your flow to ensure that your metadata gets refreshed every 15 minutes: # ingestion_flow.py from datetime import timedelta from prefect.deployments import DeploymentSpec from prefect.flow_runners import SubprocessFlowRunner from prefect.orion.schemas.schedules import IntervalSchedule from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in tests/test_flows.py\"\"\" DeploymentSpec ( name = \"openmetadata-dev\" , flow = ingest_metadata , parameters = dict ( config = json_config ), flow_runner = SubprocessFlowRunner (), schedule = IntervalSchedule ( interval = timedelta ( minutes = 15 )), ) Here is an explanation of the DeploymentSpec arguments: name - specifies the name of the deployment - you could use it to differentiate between a deployment for development and production environment flow - points to the flow object, i.e. the flow function name flow_runner - specifies how the flow run should be deployed; this allows you to deploy the flow run as a docker container, a Kubernetes job, or as a local subprocess - for example, you can deploy it as a subprocess running in a Conda virtual environment named \"openmetadata\" using the syntax: SubprocessFlowRunner ( condaenv = \"openmetadata\" ) schedule - allows you to choose and customize your desired schedule class; in this example, we are using a simple IntervalSchedule triggering a new flow run every 15 minutes. With the asynchronous scheduling service in Prefect 2.0, you could even schedule your flow to run every 10 seconds if you need your metadata to be always up-to-date. To deploy this scheduled workflow to Prefect, run the following command from your CLI: prefect deployment create ingestion_flow . py Deploy Prefect OpenMetadata ingestion flows So far, we\u2019ve looked at how you can create and schedule your workflow, but where does this code actually run? This is a place where the concepts of storage , work queues, and agents become important. But don\u2019t worry - all you need to know to get started is running one CLI command for each of those concepts. 1) Storage Storage is used to tell Prefect where your workflow code lives. To configure storage, run: prefect storage create The CLI will guide you through the process to select the storage of your choice - to get started you can select the Local Storage and choose some path in your file system. You can then directly select it as your default storage. 2) Work Queue Work queues collect scheduled runs and agents pick those up from the queue. To create a default work queue, run: prefect work - queue create default 3) Agent Agents are lightweight processes that poll their work queues for scheduled runs and execute workflows on the infrastructure you specified on the DeploymentSpec \u2019s flow_runner . To create an agent corresponding to the default work queue, run: prefect agent start default That\u2019s all you need! Once you have executed those three commands, your scheduled deployments ( such as the one we defined using ingestion_flow.py above ) are now scheduled, and Prefect will ensure that your metadata stays up-to-date. You can observe the state of your metadata ingestion workflows from the Prefect Orion UI . The UI will also include detailed logs showing which metadata got updated to ensure your data platform remains healthy and observable. Using Prefect 2.0 in the Cloud If you want to move beyond this local installation, you can deploy Prefect 2.0 to run your OpenMetadata ingestion workflows by: self-hosting the orchestration layer - see the list of resources on Prefect Discourse , or signing up for Prefect Cloud 2.0 - the following page will walk you through the process. For various deployment options of OpenMetadata, check the \u201cDeploy\u201d section of this documentation . Questions about using OpenMetadata with Prefect If you have any questions about configuring Prefect, post your question on Prefect Discourse or in the Prefect Community Slack . And if you need support for OpenMetadata, get in touch on OpenMetadata Slack .","title":"Schedule ingestion flow"},{"location":"schedule_ingestion_flow/#schedule-and-deploy-metadata-ingestion-flows","text":"","title":"Schedule and deploy metadata ingestion flows"},{"location":"schedule_ingestion_flow/#schedule-your-openmetadata-ingestion-flows-with-prefect","text":"Ingesting your data via manually executed scripts is great for initial exploration, but in order to build a reliable metadata platform, you need to run those workflows on a regular cadence. That\u2019s where you can leverage Prefect schedules and deployments . Here is how you can add a DeploymentSpec to your flow to ensure that your metadata gets refreshed every 15 minutes: # ingestion_flow.py from datetime import timedelta from prefect.deployments import DeploymentSpec from prefect.flow_runners import SubprocessFlowRunner from prefect.orion.schemas.schedules import IntervalSchedule from prefect_openmetadata.flows import ingest_metadata json_config = \"\"\"See an example in tests/test_flows.py\"\"\" DeploymentSpec ( name = \"openmetadata-dev\" , flow = ingest_metadata , parameters = dict ( config = json_config ), flow_runner = SubprocessFlowRunner (), schedule = IntervalSchedule ( interval = timedelta ( minutes = 15 )), ) Here is an explanation of the DeploymentSpec arguments: name - specifies the name of the deployment - you could use it to differentiate between a deployment for development and production environment flow - points to the flow object, i.e. the flow function name flow_runner - specifies how the flow run should be deployed; this allows you to deploy the flow run as a docker container, a Kubernetes job, or as a local subprocess - for example, you can deploy it as a subprocess running in a Conda virtual environment named \"openmetadata\" using the syntax: SubprocessFlowRunner ( condaenv = \"openmetadata\" ) schedule - allows you to choose and customize your desired schedule class; in this example, we are using a simple IntervalSchedule triggering a new flow run every 15 minutes. With the asynchronous scheduling service in Prefect 2.0, you could even schedule your flow to run every 10 seconds if you need your metadata to be always up-to-date. To deploy this scheduled workflow to Prefect, run the following command from your CLI: prefect deployment create ingestion_flow . py","title":"Schedule your OpenMetadata ingestion flows with Prefect"},{"location":"schedule_ingestion_flow/#deploy-prefect-openmetadata-ingestion-flows","text":"So far, we\u2019ve looked at how you can create and schedule your workflow, but where does this code actually run? This is a place where the concepts of storage , work queues, and agents become important. But don\u2019t worry - all you need to know to get started is running one CLI command for each of those concepts. 1) Storage Storage is used to tell Prefect where your workflow code lives. To configure storage, run: prefect storage create The CLI will guide you through the process to select the storage of your choice - to get started you can select the Local Storage and choose some path in your file system. You can then directly select it as your default storage. 2) Work Queue Work queues collect scheduled runs and agents pick those up from the queue. To create a default work queue, run: prefect work - queue create default 3) Agent Agents are lightweight processes that poll their work queues for scheduled runs and execute workflows on the infrastructure you specified on the DeploymentSpec \u2019s flow_runner . To create an agent corresponding to the default work queue, run: prefect agent start default That\u2019s all you need! Once you have executed those three commands, your scheduled deployments ( such as the one we defined using ingestion_flow.py above ) are now scheduled, and Prefect will ensure that your metadata stays up-to-date. You can observe the state of your metadata ingestion workflows from the Prefect Orion UI . The UI will also include detailed logs showing which metadata got updated to ensure your data platform remains healthy and observable.","title":"Deploy Prefect OpenMetadata ingestion flows"},{"location":"schedule_ingestion_flow/#using-prefect-20-in-the-cloud","text":"If you want to move beyond this local installation, you can deploy Prefect 2.0 to run your OpenMetadata ingestion workflows by: self-hosting the orchestration layer - see the list of resources on Prefect Discourse , or signing up for Prefect Cloud 2.0 - the following page will walk you through the process. For various deployment options of OpenMetadata, check the \u201cDeploy\u201d section of this documentation .","title":"Using Prefect 2.0 in the Cloud"},{"location":"schedule_ingestion_flow/#questions-about-using-openmetadata-with-prefect","text":"If you have any questions about configuring Prefect, post your question on Prefect Discourse or in the Prefect Community Slack . And if you need support for OpenMetadata, get in touch on OpenMetadata Slack .","title":"Questions about using OpenMetadata with Prefect"}]}